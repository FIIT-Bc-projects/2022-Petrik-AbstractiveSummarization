{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sebastian Petrik - Stranasum - Final evaluation module\n",
    "\n",
    "This module is intended for final evaluation of models produced by Stranasum Development module, along of existing models from huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install evaluate rouge_score bert_score contractions transformers[sentencepiece] --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import evaluate\n",
    "import bert_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import contractions\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import rouge_score\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "CONFIG = dict(\n",
    "    # hf transformers of direct path to stranasum otherwise\n",
    "    model = \"\",\n",
    "    path = \"./summarizer_module\",\n",
    "    ds = 'gigaword'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ds\n",
    "\n",
    "eval_set = None\n",
    "\n",
    "if CONFIG['ds'] == 'gigaword':\n",
    "    # gigaword_stranasum_test = pd.read_csv(f\"../input/stranasum-gigaword-70-to-25/gigaword_test.csv\")\n",
    "    eval_set = load_dataset(\"gigaword\", split=\"test\").to_pandas().rename(columns={'document': 'article'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    \n",
    "    # Text cleanup\n",
    "    def clean_text(self, text: str):\n",
    "\n",
    "        # lowercase\n",
    "        text = str(text).lower()\n",
    "\n",
    "        # remove &-escaped characters\n",
    "        text = re.sub(r\"&.[1-9]+;\",\" \", str(text))\n",
    "\n",
    "        # remove escaped characters\n",
    "        text=re.sub(\"(\\\\t)\", ' ', str(text))\n",
    "        text=re.sub(\"(\\\\r)\", ' ', str(text))\n",
    "        text=re.sub(\"(\\\\n)\", ' ', str(text))\n",
    "\n",
    "        # remove double characters\n",
    "        text=re.sub(\"(__+)\", ' ', str(text))  #remove _ if it occurs more than one time consecutively\n",
    "        text=re.sub(\"(--+)\", ' ', str(text))   #remove - if it occurs more than one time consecutively\n",
    "        text=re.sub(\"(~~+)\", ' ', str(text))   #remove ~ if it occurs more than one time consecutively\n",
    "        text=re.sub(\"(\\+\\++)\", ' ', str(text))  #remove + if it occurs more than one time consecutively\n",
    "        text=re.sub(\"(\\.\\.+)\", ' ', str(text))  #remove . if it occurs more than one time consecutively\n",
    "        \n",
    "        # special - fix u.s. contraction in gigaword\n",
    "        text = re.sub(\"(u\\.s\\.)\", 'united states', str(text))\n",
    "        \n",
    "        # fix contractions to base form\n",
    "        text = contractions.fix(text)\n",
    "\n",
    "        #remove special tokens <>()|&©ø\"',;?~*!\n",
    "        text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(text)).lower()\n",
    "\n",
    "        # CNN mail data cleanup\n",
    "        text=re.sub(\"(mailto:)\", ' ', str(text)) #remove mailto:\n",
    "        text=re.sub(r\"(\\\\x9\\d)\", ' ', str(text)) #remove \\x9* in text\n",
    "        text=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(text)) #replace INC nums to INC_NUM\n",
    "        text=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(text)) #replace CM# and CHG# to CM_NUM\n",
    "\n",
    "        # url replacement into base form\n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(text))\n",
    "            repl_url = url.group(3)\n",
    "            text = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(text))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # handle dot at the end of words\n",
    "        text=re.sub(\"(\\.\\s+)\", ' ', str(text)) # remove\n",
    "        \n",
    "        text=re.sub(\"(\\-\\s+)\", ' ', str(text)) #remove - at end of words(not between)\n",
    "        text=re.sub(\"(\\:\\s+)\", ' ', str(text)) #remove : at end of words(not between)\n",
    "\n",
    "        #remove multiple spaces\n",
    "        text=re.sub(\"(\\s+)\",' ',str(text))\n",
    "\n",
    "        # apply lowercase again\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # remove trailing dot, we will apply end of sequence anyway\n",
    "        text = re.sub(\"(\\.)$\", '', str(text)).strip()\n",
    "        \n",
    "        # gigaword - UNK token\n",
    "        text = re.sub(\"unk\", '', str(text).strip())\n",
    "        \n",
    "        # gigaword - change numbers to hashtags\n",
    "        text = re.sub(\"\\d\", \"#\", str(text).strip())\n",
    "\n",
    "        return text\n",
    "\n",
    "    def apply_special_tokens(self, text):\n",
    "        text = str(text).strip()\n",
    "        text = \"<sos> \" + str(text).strip() + \" <eos>\"\n",
    "        return text\n",
    "\n",
    "    def remove_special_tokens(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "processor = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Stranasum summarization class using loadable TF graph model an processing\n",
    "class Summarizer:\n",
    "    \n",
    "    # Initialize using SummarizationModule or loaded graph tf module\n",
    "    def __init__(self, module: tf.Module):\n",
    "        self.module = module\n",
    "        self.processor = TextProcessor()\n",
    "        \n",
    "    def summarize(self, text: str):\n",
    "        prepared = self.processor.apply_special_tokens(self.processor.clean_text(text))\n",
    "        output_text, output_tensor, weights = self.module.predict(tf.constant([prepared]))\n",
    "        return prepared, self.processor.remove_special_tokens(bytes.decode(output_text.numpy())), output_tensor, weights\n",
    "    \n",
    "    # Shorthand for text output only\n",
    "    def __call__(self, text: str):\n",
    "        return self.summarize(text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = None, None\n",
    "summarize = None\n",
    "\n",
    "if CONFIG['model'] == \"google/pegasus-xsum\":\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(CONFIG['model'])\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(CONFIG['model']).to(device)\n",
    "    \n",
    "    def hf_sum(src_text):\n",
    "        batch = tokenizer(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "        translated = model.generate(**batch, max_new_tokens=25)\n",
    "        tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "        return processor.clean_text(tgt_text[0])\n",
    "    \n",
    "    summarize = hf_sum\n",
    "\n",
    "elif CONFIG['model'] == \"google/roberta2roberta_L-24_gigaword\":\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_gigaword\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"google/roberta2roberta_L-24_gigaword\").to(device)\n",
    "    \n",
    "    def hf_sum(src_text):\n",
    "        batch = tokenizer(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "        translated = model.generate(**batch, max_new_tokens=25)\n",
    "        tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "        return processor.clean_text(tgt_text[0])\n",
    "    \n",
    "    summarize = hf_sum\n",
    "\n",
    "elif CONFIG['model'] == \"a1noack/bart-large-gigaword\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"a1noack/bart-large-gigaword\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"a1noack/bart-large-gigaword\").to(device)    \n",
    "    def hf_sum(src_text):\n",
    "        batch = tokenizer(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "        translated = model.generate(**batch, max_new_tokens=25)\n",
    "        tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "        return processor.clean_text(tgt_text[0])\n",
    "    \n",
    "    summarize = hf_sum\n",
    "\n",
    "else:\n",
    "    # stranasum\n",
    "    model = tf.saved_model.load(CONFIG['path'])\n",
    "    summarize = Summarizer(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test summarization\n",
    "eval_set['summary'].iloc[1], summarize(eval_set['article'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize with processor\n",
    "summarize(processor.clean_text(eval_set['article'].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_frame(frame):\n",
    "    for i in range(0, frame.shape[0]):\n",
    "        frame.iloc[i, frame.columns.get_loc('summary')] = processor.clean_text(frame.iloc[i]['summary'])\n",
    "    return frame\n",
    "\n",
    "eval_frame = clean_frame(eval_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_frame(frame, summarize_fn):\n",
    "    \n",
    "    frame = frame.copy()\n",
    "    frame['predicted'] = '<NONE>'\n",
    "    \n",
    "    for i in range(0, frame.shape[0]):\n",
    "        if i%100 == 0:\n",
    "            print(f\"Summarising ... {i}/{frame.shape[0]}\")\n",
    "            \n",
    "        frame.iloc[i, frame.columns.get_loc('predicted')] = summarize_fn(frame.iloc[i]['article'])\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_frame = summarize_frame(eval_frame, summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_full(\n",
    "        predictions, references, rouge_types=None, use_aggregator=True\n",
    "    ):\n",
    "        if rouge_types is None:\n",
    "            rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "        \n",
    "        multi_ref = isinstance(references[0], list)\n",
    "            \n",
    "        scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types)\n",
    "        \n",
    "        if use_aggregator:\n",
    "            aggregator = rouge_score.scoring.BootstrapAggregator()\n",
    "        else:\n",
    "            scores = []\n",
    "\n",
    "        for ref, pred in zip(references, predictions):\n",
    "            if multi_ref:\n",
    "                score = scorer.score_multi(ref, pred)\n",
    "            else:\n",
    "                score = scorer.score(ref, pred)\n",
    "            if use_aggregator:\n",
    "                aggregator.add_scores(score)\n",
    "            else:\n",
    "                scores.append(score)\n",
    "\n",
    "        if use_aggregator:\n",
    "            result = aggregator.aggregate()\n",
    "            for key in result:\n",
    "                result[key] = result[key].mid\n",
    "\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in scores[0]:\n",
    "                result[key] = list(score[key] for score in scores)\n",
    "                \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics evaluation\n",
    "\n",
    "bleu_metric = evaluate.load('bleu')\n",
    "bertscore_metric = evaluate.load('bertscore')\n",
    "# rouge_metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotbins(x):\n",
    "    plt.hist(x, bins=100)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_frame(frame: pd.DataFrame):\n",
    "    preds = frame['predicted']\n",
    "    refs = frame['summary']\n",
    "    # rouge = rouge_metric.compute(references=refs, predictions=preds)\n",
    "    bleu = bleu_metric.compute(references=refs, predictions=preds)\n",
    "    rouge= rouge_full(references=refs, predictions=preds)\n",
    "    \n",
    "    # BP, BR, BF = bert_score.score(frame['predicted'], frame['summary'], lang=\"en\", verbose=True)\n",
    "    bertscore = bertscore_metric.compute(references=refs, predictions=preds, lang=\"en\", verbose=True)\n",
    "\n",
    "    b = dict(\n",
    "        p = np.average(bertscore['precision']),\n",
    "        r = np.average(bertscore['recall']),\n",
    "        f = np.average(bertscore['f1'])\n",
    "    )\n",
    "\n",
    "    r = lambda x: f\"{x:.3f}\"\n",
    "    rprf = lambda x: f\"{r(rouge[x].precision)} & {r(rouge[x].recall)} & {r(rouge[x].fmeasure)}\"\n",
    "    \n",
    "    print(\"\\n---------\")\n",
    "    print(CONFIG)\n",
    "    \n",
    "    print(f\"{CONFIG['model']} & {r(bleu['bleu'])} & {rprf('rouge1')} & {rprf('rouge2')} & {rprf('rougeL')}\")\n",
    "    \n",
    "    print(f\"{CONFIG['model']} & m & {rprf('rougeLsum')} & {r(b['p'])} & {r(b['r'])} & {r(b['f'])}\")\n",
    "    \n",
    "    print(\"---------\\n\")\n",
    "    \n",
    "    return bleu, rouge, b\n",
    "\n",
    "evaluate_frame(eval_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_summaries(frame):\n",
    "    \n",
    "    for i, row in frame.iterrows():\n",
    "        print(f\"\\n ------------------\")\n",
    "        print(f\"Article  : {row['article']}\")\n",
    "        print(f\"\\nSummary  : {row['summary']}\")\n",
    "        print(f\"\\nPredicted: {row['predicted']}\")\n",
    "        print()\n",
    "        print(f\"------------------\")\n",
    "        \n",
    "pretty_summaries(eval_frame[100:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
