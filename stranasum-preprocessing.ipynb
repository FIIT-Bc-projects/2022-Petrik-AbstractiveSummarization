{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sebastian Petrik - Stranasum - Data preparation module"]},{"cell_type":"markdown","metadata":{},"source":["Datasets preprocessing, train-validation-test split, output as prepared frame with special tokens, ready for tokenization and training / inference / evaluation."]},{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:56:50.576468Z","iopub.status.busy":"2023-03-21T12:56:50.575401Z","iopub.status.idle":"2023-03-21T12:56:50.582442Z","shell.execute_reply":"2023-03-21T12:56:50.581115Z","shell.execute_reply.started":"2023-03-21T12:56:50.576409Z"},"trusted":true},"outputs":[],"source":["# seed for random generators\n","SEED = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:42.784591Z","iopub.status.busy":"2023-03-21T12:20:42.784100Z","iopub.status.idle":"2023-03-21T12:20:56.049546Z","shell.execute_reply":"2023-03-21T12:20:56.048230Z","shell.execute_reply.started":"2023-03-21T12:20:42.784550Z"},"trusted":true},"outputs":[],"source":["!pip install openpyxl contractions --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:56.052463Z","iopub.status.busy":"2023-03-21T12:20:56.052002Z","iopub.status.idle":"2023-03-21T12:20:56.060549Z","shell.execute_reply":"2023-03-21T12:20:56.059079Z","shell.execute_reply.started":"2023-03-21T12:20:56.052418Z"},"trusted":true},"outputs":[],"source":["import os\n","print(os.environ.get('KAGGLE_CONTAINER_NAME')) # check if kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:56.062490Z","iopub.status.busy":"2023-03-21T12:20:56.062126Z","iopub.status.idle":"2023-03-21T12:20:56.082820Z","shell.execute_reply":"2023-03-21T12:20:56.081417Z","shell.execute_reply.started":"2023-03-21T12:20:56.062456Z"},"trusted":true},"outputs":[],"source":["import pkg_resources\n","sorted(list(filter(\n","    lambda x: x[0] in ['numpy', 'pandas', 'tensorflow', 'tensorflow-text', 'keras', 'tensorflow-estimator', 'tensorflow-datasets', 'contractions'],\n","    [(i.key, i.version) for i in pkg_resources.working_set]\n",")))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:56.087223Z","iopub.status.busy":"2023-03-21T12:20:56.085895Z","iopub.status.idle":"2023-03-21T12:20:56.115278Z","shell.execute_reply":"2023-03-21T12:20:56.113862Z","shell.execute_reply.started":"2023-03-21T12:20:56.087167Z"},"trusted":true},"outputs":[],"source":["# Imports\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","from collections import defaultdict\n","import string\n","import tensorflow as tf\n","import re\n","import os\n","import time\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import operator as op\n","import spacy\n","import contractions"]},{"cell_type":"markdown","metadata":{},"source":["## Data loading"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:56.118123Z","iopub.status.busy":"2023-03-21T12:20:56.117542Z","iopub.status.idle":"2023-03-21T12:20:59.825695Z","shell.execute_reply":"2023-03-21T12:20:59.824357Z","shell.execute_reply.started":"2023-03-21T12:20:56.118043Z"},"trusted":true},"outputs":[],"source":["# show available data\n","!ls ../input\n","!ls ../input/inshorts-news-data\n","!ls ../input/news-summarization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:20:59.828398Z","iopub.status.busy":"2023-03-21T12:20:59.827611Z","iopub.status.idle":"2023-03-21T12:21:08.896501Z","shell.execute_reply":"2023-03-21T12:21:08.895132Z","shell.execute_reply.started":"2023-03-21T12:20:59.828350Z"},"trusted":true},"outputs":[],"source":["# Inshorts XLS dataset\n","inshorts_raw = pd.read_excel(\"../input/inshorts-news-data/Inshorts Cleaned Data.xlsx\",engine = 'openpyxl')\n","inshorts_raw.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\n","inshorts_raw"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:21:08.899051Z","iopub.status.busy":"2023-03-21T12:21:08.898262Z","iopub.status.idle":"2023-03-21T12:22:48.114003Z","shell.execute_reply":"2023-03-21T12:22:48.111913Z","shell.execute_reply.started":"2023-03-21T12:21:08.899009Z"},"trusted":true},"outputs":[],"source":["# combined 3 datasets 4GB\n","news_sum_combined = pd.read_csv('../input/news-summarization/data.csv')\n","news_sum_combined.drop(columns=news_sum_combined.columns[0], axis=1, inplace=True) # drop index col\n","news_sum_combined"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:22:48.118405Z","iopub.status.busy":"2023-03-21T12:22:48.117579Z","iopub.status.idle":"2023-03-21T12:22:48.158614Z","shell.execute_reply":"2023-03-21T12:22:48.157361Z","shell.execute_reply.started":"2023-03-21T12:22:48.118352Z"},"trusted":true},"outputs":[],"source":["class Preprocessor:\n","    \n","    def __init__(self, dot_token_enabled=True):\n","        self.dot_token_enabled = dot_token_enabled\n","    \n","    # Text cleanup\n","    def clean_text(self, text: str):\n","\n","        # lowercase\n","        text = str(text).lower()\n","\n","        # remove &-escaped characters\n","        text = re.sub(r\"&.[1-9]+;\",\" \", str(text))\n","\n","        # remove escaped characters\n","        text=re.sub(\"(\\\\t)\", ' ', str(text))\n","        text=re.sub(\"(\\\\r)\", ' ', str(text))\n","        text=re.sub(\"(\\\\n)\", ' ', str(text))\n","\n","        # remove double characters\n","        text=re.sub(\"(__+)\", ' ', str(text))  #remove _ if it occurs more than one time consecutively\n","        text=re.sub(\"(--+)\", ' ', str(text))   #remove - if it occurs more than one time consecutively\n","        text=re.sub(\"(~~+)\", ' ', str(text))   #remove ~ if it occurs more than one time consecutively\n","        text=re.sub(\"(\\+\\++)\", ' ', str(text))  #remove + if it occurs more than one time consecutively\n","        text=re.sub(\"(\\.\\.+)\", ' ', str(text))  #remove . if it occurs more than one time consecutively\n","        \n","        # fix contractions to base form\n","        text = contractions.fix(text)\n","\n","        #remove special tokens <>()|&©ø\"',;?~*!\n","        text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(text)).lower()\n","\n","        # CNN mail data cleanup\n","        text=re.sub(\"(mailto:)\", ' ', str(text)) #remove mailto:\n","        text=re.sub(r\"(\\\\x9\\d)\", ' ', str(text)) #remove \\x9* in text\n","        text=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(text)) #replace INC nums to INC_NUM\n","        text=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(text)) #replace CM# and CHG# to CM_NUM\n","\n","        # url replacement into base form\n","        try:\n","            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(text))\n","            repl_url = url.group(3)\n","            text = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(text))\n","        except:\n","            pass\n","\n","\n","        # handle dot at the end of words\n","        if self.dot_token_enabled:\n","            text=re.sub(\"(\\.\\s+)\", ' . ', str(text))\n","        else:\n","            text=re.sub(\"(\\.\\s+)\", ' ', str(text)) # or completely remove\n","        \n","        text=re.sub(\"(\\-\\s+)\", ' ', str(text)) #remove - at end of words(not between)\n","        text=re.sub(\"(\\:\\s+)\", ' ', str(text)) #remove : at end of words(not between)\n","\n","        #remove multiple spaces\n","        text=re.sub(\"(\\s+)\",' ',str(text))\n","\n","        # apply lowercase again\n","        text = text.lower().strip()\n","        \n","        # remove trailing dot, we will apply end of sequence anyway\n","        text = re.sub(\"(\\.)$\", '', str(text)).strip()\n","\n","        return text\n","\n","    def apply_special_tokens(self, text):\n","        text = str(text).strip()\n","        text = \"<sos> \" + str(text).strip() + \" <eos>\"\n","        \n","#         if self.dot_token_enabled:\n","#             text = text.replace(\".\", \"<dot>\")\n","        \n","        return text\n","\n","    def remove_special_tokens(self, text):\n","        text = text.lower()\n","        text = text.replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n","        text = text.replace(\"<unk>\", \"##\")\n","#         text = text.replace(\"<dot>\", \". \") # normal syntax with dot at end\n","        text = text.strip()\n","        return text\n","\n","    def plot_approx_lengths(self, df: pd.DataFrame):\n","        sns.displot(df['article_len_approx']), sns.displot(df['summary_len_approx'])\n","\n","    # preprocess sentence dataframe from raw format - clean, apply sos/eos tokens\n","    # - removes articles with length outside bounds\n","    def preprocess_frame(self, df: pd.DataFrame, article_len_range, summary_len_range):\n","        \n","        print(\"Preprocessing frame...\")\n","\n","        # apply text cleaning\n","        df['article'] = df['article'].apply(self.clean_text)\n","        df['summary'] = df['summary'].apply(self.clean_text)\n","\n","        # apply special tokens\n","        df['article'] = df['article'].apply(self.apply_special_tokens)\n","        df['summary'] = df['summary'].apply(self.apply_special_tokens)\n","\n","        # simple text length approximation for analysis\n","        df['article_len_approx'] = df['article'].apply(lambda x: op.countOf(x, ' '))\n","        df['summary_len_approx'] = df['summary'].apply(lambda x: op.countOf(x, ' '))\n","        \n","        print(\"Original length distribution:\")\n","        self.plot_approx_lengths(df)\n","\n","        # remove longer than set length\n","        article_min, article_max = article_len_range\n","        summary_min, summary_max = summary_len_range\n","        \n","        df = df[\n","            (df['article_len_approx'] <= article_max) &\n","            (df['article_len_approx'] >= article_min) &\n","            (df['summary_len_approx'] <= summary_max) &\n","            (df['summary_len_approx'] >= summary_min)\n","        ]\n","\n","        # print plots\n","        print(\"After processing length distribution:\")\n","        self.plot_approx_lengths(df)\n","\n","        return df\n","    \n","preprocessor = Preprocessor(dot_token_enabled=False)\n","\n","# Test\n","preprocessor.clean_text(\"  This text (my text ) isn't ]] very - clean.  it WOULd'Ve been betteR? if, it was ok  \")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:22:48.160460Z","iopub.status.busy":"2023-03-21T12:22:48.160129Z","iopub.status.idle":"2023-03-21T12:22:48.184679Z","shell.execute_reply":"2023-03-21T12:22:48.183338Z","shell.execute_reply.started":"2023-03-21T12:22:48.160429Z"},"trusted":true},"outputs":[],"source":["preprocessor.apply_special_tokens(preprocessor.clean_text(inshorts_raw.iloc[100]['Short']))"]},{"cell_type":"markdown","metadata":{},"source":["## Inshorts dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:22:48.188909Z","iopub.status.busy":"2023-03-21T12:22:48.188427Z","iopub.status.idle":"2023-03-21T12:22:59.932551Z","shell.execute_reply":"2023-03-21T12:22:59.931218Z","shell.execute_reply.started":"2023-03-21T12:22:48.188871Z"},"trusted":true},"outputs":[],"source":["df_inshorts = preprocessor.preprocess_frame(\n","        inshorts_raw.rename({\"Short\": \"article\", \"Headline\": \"summary\"}, axis=1).reset_index(drop=True),\n","        (10, 70),\n","        (3, 16)\n",")\n","print(df_inshorts.describe())\n","df_inshorts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:22:59.935698Z","iopub.status.busy":"2023-03-21T12:22:59.934746Z","iopub.status.idle":"2023-03-21T12:25:36.713033Z","shell.execute_reply":"2023-03-21T12:25:36.711616Z","shell.execute_reply.started":"2023-03-21T12:22:59.935646Z"},"trusted":true},"outputs":[],"source":["# Newssum combined -> get xsum\n","print('News sum available datasets:', news_sum_combined.groupby('Dataset')['Dataset'].count())\n","\n","xsum_raw = news_sum_combined[ news_sum_combined['Dataset'] == 'XSum' ]\n","\n","print('Preparing xsum ...')\n","df_xsum = preprocessor.preprocess_frame(\n","    xsum_raw.rename({\"Content\": \"article\", \"Summary\": \"summary\"}, axis=1).reset_index(drop=True),\n","    (10, 300),\n","    (3, 40)\n",")\n","print(df_xsum.describe())\n","df_xsum"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Preparing xsum shorter ...')\n","df_xsum_shorter = preprocessor.preprocess_frame(\n","    xsum_raw.rename({\"Content\": \"article\", \"Summary\": \"summary\"}, axis=1).reset_index(drop=True),\n","    (10, 150),\n","    (3, 40)\n",")\n","print(df_xsum_shorter.describe())\n","df_xsum_shorter"]},{"cell_type":"markdown","metadata":{},"source":["## Assemble final train, validation and test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:25:36.714968Z","iopub.status.busy":"2023-03-21T12:25:36.714651Z","iopub.status.idle":"2023-03-21T12:25:36.727105Z","shell.execute_reply":"2023-03-21T12:25:36.726097Z","shell.execute_reply.started":"2023-03-21T12:25:36.714937Z"},"trusted":true},"outputs":[],"source":["#  drop articles with only one member of length category, this will allow stratified split\n","def ensure_min_summary_length_group_size(df: pd.DataFrame):\n","    df = df[df.groupby('article_len_approx').summary_len_approx.transform('count') > 1]\n","    return df\n","\n","# Stratified split into train, validation, test by article length\n","def stratified_triple_split_by_article(df: pd.DataFrame, test_size=0.1, val_size=0.1):\n","    df = ensure_min_summary_length_group_size(df)\n","    df_trainval, df_test = train_test_split(\n","        df,\n","        test_size=test_size, \n","        stratify=df['article_len_approx'],\n","        random_state=SEED\n","    )\n","    df_trainval.shape, df_test.shape\n","\n","    # split train+val to train and validation,\n","    # relative original full set with test set is 1.1 so we multiply the ratio to get ~|test|\n","\n","    df_trainval = ensure_min_summary_length_group_size(df_trainval)\n","    df_train, df_val = train_test_split(\n","        df_trainval,\n","        test_size=val_size * (1 + test_size),\n","        stratify=df_trainval['article_len_approx'],\n","        random_state=SEED\n","    )\n","\n","    return df_train, df_val, df_test\n","\n","def save_dataset(name: str, val_size: int, test_size: int, frame: int):\n","    \n","    print('Saving dataset ' + name)\n","    \n","    frame = frame[['article', 'summary', 'article_len_approx', 'summary_len_approx']].reset_index(drop=True)\n","    \n","    train, val, test = df_train, df_val, df_test = stratified_triple_split_by_article(\n","        frame,\n","        test_size=test_size,\n","        val_size=val_size\n","    )\n","    \n","    print(f\"Train:      {train.shape} - {1 - test_size - val_size}\")\n","    print(f\"Validation: {val.shape} - {val_size}\")\n","    print(f\"Test:       {test.shape} - {test_size}\")\n","    \n","    train.to_csv(name + f\"_v{val_size}_t{test_size}_train.csv\")\n","    val.to_csv(name + f\"_v{val_size}_t{test_size}_val.csv\")\n","    test.to_csv(name + f\"_v{val_size}_t{test_size}_test.csv\")\n","    \n","    print('Split and saved dataset ' + name)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:25:36.728974Z","iopub.status.busy":"2023-03-21T12:25:36.728631Z","iopub.status.idle":"2023-03-21T12:25:41.306434Z","shell.execute_reply":"2023-03-21T12:25:41.304859Z","shell.execute_reply.started":"2023-03-21T12:25:36.728917Z"},"trusted":true},"outputs":[],"source":["# save inshorts\n","save_dataset('inshorts_10-70_3-16', 0.1, 0.1, df_inshorts)\n","save_dataset('inshorts_10-70_3-16', 0.05, 0.05, df_inshorts)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:25:41.308959Z","iopub.status.busy":"2023-03-21T12:25:41.308462Z","iopub.status.idle":"2023-03-21T12:26:05.104836Z","shell.execute_reply":"2023-03-21T12:26:05.103390Z","shell.execute_reply.started":"2023-03-21T12:25:41.308907Z"},"trusted":true},"outputs":[],"source":["# save xsum\n","save_dataset('xsum_10-300_3-40', 0.1, 0.1, df_xsum)\n","save_dataset('xsum_10-300_3-40', 0.05, 0.05, df_xsum)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save xsum shorter\n","save_dataset('xsum_10-150_3-40', 0.1, 0.1, df_xsum_shorter)\n","save_dataset('xsum_10-150_3-40', 0.05, 0.05, df_xsum_shorter)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:26:05.108268Z","iopub.status.busy":"2023-03-21T12:26:05.107140Z","iopub.status.idle":"2023-03-21T12:26:06.538850Z","shell.execute_reply":"2023-03-21T12:26:06.537477Z","shell.execute_reply.started":"2023-03-21T12:26:05.108208Z"},"trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T12:26:34.324205Z","iopub.status.busy":"2023-03-21T12:26:34.323676Z","iopub.status.idle":"2023-03-21T12:26:34.331706Z","shell.execute_reply":"2023-03-21T12:26:34.330166Z","shell.execute_reply.started":"2023-03-21T12:26:34.324156Z"},"trusted":true},"outputs":[],"source":["print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
