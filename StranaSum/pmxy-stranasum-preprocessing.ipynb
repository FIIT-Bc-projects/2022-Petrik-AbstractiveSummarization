{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sebastian Petrik - Abstractive summarization - Data preparation and preprocessing","metadata":{}},{"cell_type":"markdown","source":"Datasets preprocessing, train-validation-test split, output as prepared frame with special tokens, ready for tokenization and training / inference / evaluation.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# seed for random generators\nSEED = 42","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:56:50.575401Z","iopub.execute_input":"2023-03-21T12:56:50.576468Z","iopub.status.idle":"2023-03-21T12:56:50.582442Z","shell.execute_reply.started":"2023-03-21T12:56:50.576409Z","shell.execute_reply":"2023-03-21T12:56:50.581115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl contractions --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:42.784100Z","iopub.execute_input":"2023-03-21T12:20:42.784591Z","iopub.status.idle":"2023-03-21T12:20:56.049546Z","shell.execute_reply.started":"2023-03-21T12:20:42.784550Z","shell.execute_reply":"2023-03-21T12:20:56.048230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.environ.get('KAGGLE_CONTAINER_NAME')) # check if kaggle","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:56.052002Z","iopub.execute_input":"2023-03-21T12:20:56.052463Z","iopub.status.idle":"2023-03-21T12:20:56.060549Z","shell.execute_reply.started":"2023-03-21T12:20:56.052418Z","shell.execute_reply":"2023-03-21T12:20:56.059079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pkg_resources\nsorted(list(filter(\n    lambda x: x[0] in ['numpy', 'pandas', 'tensorflow', 'tensorflow-text', 'keras', 'tensorflow-estimator', 'tensorflow-datasets', 'contractions'],\n    [(i.key, i.version) for i in pkg_resources.working_set]\n)))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:56.062126Z","iopub.execute_input":"2023-03-21T12:20:56.062490Z","iopub.status.idle":"2023-03-21T12:20:56.082820Z","shell.execute_reply.started":"2023-03-21T12:20:56.062456Z","shell.execute_reply":"2023-03-21T12:20:56.081417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom collections import defaultdict\nimport string\nimport tensorflow as tf\nimport re\nimport os\nimport time\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport operator as op\nimport spacy\nimport contractions","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:56.085895Z","iopub.execute_input":"2023-03-21T12:20:56.087223Z","iopub.status.idle":"2023-03-21T12:20:56.115278Z","shell.execute_reply.started":"2023-03-21T12:20:56.087167Z","shell.execute_reply":"2023-03-21T12:20:56.113862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading","metadata":{}},{"cell_type":"code","source":"# show available data\n!ls ../input\n!ls ../input/inshorts-news-data\n!ls ../input/news-summarization","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:56.117542Z","iopub.execute_input":"2023-03-21T12:20:56.118123Z","iopub.status.idle":"2023-03-21T12:20:59.825695Z","shell.execute_reply.started":"2023-03-21T12:20:56.118043Z","shell.execute_reply":"2023-03-21T12:20:59.824357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inshorts XLS dataset\ninshorts_raw = pd.read_excel(\"../input/inshorts-news-data/Inshorts Cleaned Data.xlsx\",engine = 'openpyxl')\ninshorts_raw.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\ninshorts_raw","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:20:59.827611Z","iopub.execute_input":"2023-03-21T12:20:59.828398Z","iopub.status.idle":"2023-03-21T12:21:08.896501Z","shell.execute_reply.started":"2023-03-21T12:20:59.828350Z","shell.execute_reply":"2023-03-21T12:21:08.895132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combined 3 datasets 4GB\nnews_sum_combined = pd.read_csv('../input/news-summarization/data.csv')\nnews_sum_combined.drop(columns=news_sum_combined.columns[0], axis=1, inplace=True) # drop index col\nnews_sum_combined","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:21:08.898262Z","iopub.execute_input":"2023-03-21T12:21:08.899051Z","iopub.status.idle":"2023-03-21T12:22:48.114003Z","shell.execute_reply.started":"2023-03-21T12:21:08.899009Z","shell.execute_reply":"2023-03-21T12:22:48.111913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"class Preprocessor:\n    \n    def __init__(self, dot_token_enabled=True):\n        self.dot_token_enabled = dot_token_enabled\n    \n    # Text cleanup\n    def clean_text(self, text: str):\n\n        # lowercase\n        text = str(text).lower()\n\n        # remove &-escaped characters\n        text = re.sub(r\"&.[1-9]+;\",\" \", str(text))\n\n        # remove escaped characters\n        text=re.sub(\"(\\\\t)\", ' ', str(text))\n        text=re.sub(\"(\\\\r)\", ' ', str(text))\n        text=re.sub(\"(\\\\n)\", ' ', str(text))\n\n        # remove double characters\n        text=re.sub(\"(__+)\", ' ', str(text))  #remove _ if it occurs more than one time consecutively\n        text=re.sub(\"(--+)\", ' ', str(text))   #remove - if it occurs more than one time consecutively\n        text=re.sub(\"(~~+)\", ' ', str(text))   #remove ~ if it occurs more than one time consecutively\n        text=re.sub(\"(\\+\\++)\", ' ', str(text))  #remove + if it occurs more than one time consecutively\n        text=re.sub(\"(\\.\\.+)\", ' ', str(text))  #remove . if it occurs more than one time consecutively\n        \n        # fix contractions to base form\n        text = contractions.fix(text)\n\n        #remove special tokens <>()|&©ø\"',;?~*!\n        text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(text)).lower()\n\n        # CNN mail data cleanup\n        text=re.sub(\"(mailto:)\", ' ', str(text)) #remove mailto:\n        text=re.sub(r\"(\\\\x9\\d)\", ' ', str(text)) #remove \\x9* in text\n        text=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(text)) #replace INC nums to INC_NUM\n        text=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(text)) #replace CM# and CHG# to CM_NUM\n\n        # url replacement into base form\n        try:\n            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(text))\n            repl_url = url.group(3)\n            text = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(text))\n        except:\n            pass\n\n\n        # handle dot at the end of words\n        if self.dot_token_enabled:\n            text=re.sub(\"(\\.\\s+)\", ' . ', str(text))\n        else:\n            text=re.sub(\"(\\.\\s+)\", ' ', str(text)) # or completely remove\n        \n        text=re.sub(\"(\\-\\s+)\", ' ', str(text)) #remove - at end of words(not between)\n        text=re.sub(\"(\\:\\s+)\", ' ', str(text)) #remove : at end of words(not between)\n\n        #remove multiple spaces\n        text=re.sub(\"(\\s+)\",' ',str(text))\n\n        # apply lowercase again\n        text = text.lower().strip()\n        \n        # remove trailing dot, we will apply end of sequence anyway\n        text = re.sub(\"(\\.)$\", '', str(text)).strip()\n\n        return text\n\n    def apply_special_tokens(self, text):\n        text = str(text).strip()\n        text = \"<sos> \" + str(text).strip() + \" <eos>\"\n        \n#         if self.dot_token_enabled:\n#             text = text.replace(\".\", \"<dot>\")\n        \n        return text\n\n    def remove_special_tokens(self, text):\n        text = text.lower()\n        text = text.replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n        text = text.replace(\"<unk>\", \"##\")\n#         text = text.replace(\"<dot>\", \". \") # normal syntax with dot at end\n        text = text.strip()\n        return text\n\n    def plot_approx_lengths(self, df: pd.DataFrame):\n        sns.displot(df['article_len_approx']), sns.displot(df['summary_len_approx'])\n\n    # preprocess sentence dataframe from raw format - clean, apply sos/eos tokens\n    # - removes articles with length outside bounds\n    def preprocess_frame(self, df: pd.DataFrame, article_len_range, summary_len_range):\n        \n        print(\"Preprocessing frame...\")\n\n        # apply text cleaning\n        df['article'] = df['article'].apply(self.clean_text)\n        df['summary'] = df['summary'].apply(self.clean_text)\n\n        # apply special tokens\n        df['article'] = df['article'].apply(self.apply_special_tokens)\n        df['summary'] = df['summary'].apply(self.apply_special_tokens)\n\n        # simple text length approximation for analysis\n        df['article_len_approx'] = df['article'].apply(lambda x: op.countOf(x, ' '))\n        df['summary_len_approx'] = df['summary'].apply(lambda x: op.countOf(x, ' '))\n        \n        print(\"Original length distribution:\")\n        self.plot_approx_lengths(df)\n\n        # remove longer than set length\n        article_min, article_max = article_len_range\n        summary_min, summary_max = summary_len_range\n        \n        df = df[\n            (df['article_len_approx'] <= article_max) &\n            (df['article_len_approx'] >= article_min) &\n            (df['summary_len_approx'] <= summary_max) &\n            (df['summary_len_approx'] >= summary_min)\n        ]\n\n        # print plots\n        print(\"After processing length distribution:\")\n        self.plot_approx_lengths(df)\n\n        return df\n    \npreprocessor = Preprocessor(dot_token_enabled=False)\n\n# Test\npreprocessor.clean_text(\"  This text (my text ) isn't ]] very - clean.  it WOULd'Ve been betteR? if, it was ok  \")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:22:48.117579Z","iopub.execute_input":"2023-03-21T12:22:48.118405Z","iopub.status.idle":"2023-03-21T12:22:48.158614Z","shell.execute_reply.started":"2023-03-21T12:22:48.118352Z","shell.execute_reply":"2023-03-21T12:22:48.157361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor.apply_special_tokens(preprocessor.clean_text(inshorts_raw.iloc[100]['Short']))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:22:48.160129Z","iopub.execute_input":"2023-03-21T12:22:48.160460Z","iopub.status.idle":"2023-03-21T12:22:48.184679Z","shell.execute_reply.started":"2023-03-21T12:22:48.160429Z","shell.execute_reply":"2023-03-21T12:22:48.183338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inshorts dataset","metadata":{}},{"cell_type":"code","source":"df_inshorts = preprocessor.preprocess_frame(\n        inshorts_raw.rename({\"Short\": \"article\", \"Headline\": \"summary\"}, axis=1).reset_index(drop=True),\n        (10, 70),\n        (3, 16)\n)\nprint(df_inshorts.describe())\ndf_inshorts","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:22:48.188427Z","iopub.execute_input":"2023-03-21T12:22:48.188909Z","iopub.status.idle":"2023-03-21T12:22:59.932551Z","shell.execute_reply.started":"2023-03-21T12:22:48.188871Z","shell.execute_reply":"2023-03-21T12:22:59.931218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Newssum combined -> get xsum\nprint('News sum available datasets:', news_sum_combined.groupby('Dataset')['Dataset'].count())\n\nxsum_raw = news_sum_combined[ news_sum_combined['Dataset'] == 'XSum' ]\n\nprint('Preparing xsum ...')\ndf_xsum = preprocessor.preprocess_frame(\n    xsum_raw.rename({\"Content\": \"article\", \"Summary\": \"summary\"}, axis=1).reset_index(drop=True),\n    (10, 300),\n    (3, 40)\n)\nprint(df_xsum.describe())\ndf_xsum","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:22:59.934746Z","iopub.execute_input":"2023-03-21T12:22:59.935698Z","iopub.status.idle":"2023-03-21T12:25:36.713033Z","shell.execute_reply.started":"2023-03-21T12:22:59.935646Z","shell.execute_reply":"2023-03-21T12:25:36.711616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Preparing xsum shorter ...')\ndf_xsum_shorter = preprocessor.preprocess_frame(\n    xsum_raw.rename({\"Content\": \"article\", \"Summary\": \"summary\"}, axis=1).reset_index(drop=True),\n    (10, 150),\n    (3, 40)\n)\nprint(df_xsum_shorter.describe())\ndf_xsum_shorter","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assemble final train, validation and test sets","metadata":{}},{"cell_type":"code","source":"#  drop articles with only one member of length category, this will allow stratified split\ndef ensure_min_summary_length_group_size(df: pd.DataFrame):\n    df = df[df.groupby('article_len_approx').summary_len_approx.transform('count') > 1]\n    return df\n\n# Stratified split into train, validation, test by article length\ndef stratified_triple_split_by_article(df: pd.DataFrame, test_size=0.1, val_size=0.1):\n    df = ensure_min_summary_length_group_size(df)\n    df_trainval, df_test = train_test_split(\n        df,\n        test_size=test_size, \n        stratify=df['article_len_approx'],\n        random_state=SEED\n    )\n    df_trainval.shape, df_test.shape\n\n    # split train+val to train and validation,\n    # relative original full set with test set is 1.1 so we multiply the ratio to get ~|test|\n\n    df_trainval = ensure_min_summary_length_group_size(df_trainval)\n    df_train, df_val = train_test_split(\n        df_trainval,\n        test_size=val_size * (1 + test_size),\n        stratify=df_trainval['article_len_approx'],\n        random_state=SEED\n    )\n\n    return df_train, df_val, df_test\n\ndef save_dataset(name: str, val_size: int, test_size: int, frame: int):\n    \n    print('Saving dataset ' + name)\n    \n    frame = frame[['article', 'summary', 'article_len_approx', 'summary_len_approx']].reset_index(drop=True)\n    \n    train, val, test = df_train, df_val, df_test = stratified_triple_split_by_article(\n        frame,\n        test_size=test_size,\n        val_size=val_size\n    )\n    \n    print(f\"Train:      {train.shape} - {1 - test_size - val_size}\")\n    print(f\"Validation: {val.shape} - {val_size}\")\n    print(f\"Test:       {test.shape} - {test_size}\")\n    \n    train.to_csv(name + f\"_v{val_size}_t{test_size}_train.csv\")\n    val.to_csv(name + f\"_v{val_size}_t{test_size}_val.csv\")\n    test.to_csv(name + f\"_v{val_size}_t{test_size}_test.csv\")\n    \n    print('Split and saved dataset ' + name)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:25:36.714651Z","iopub.execute_input":"2023-03-21T12:25:36.714968Z","iopub.status.idle":"2023-03-21T12:25:36.727105Z","shell.execute_reply.started":"2023-03-21T12:25:36.714937Z","shell.execute_reply":"2023-03-21T12:25:36.726097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save inshorts\nsave_dataset('inshorts_10-70_3-16', 0.1, 0.1, df_inshorts)\nsave_dataset('inshorts_10-70_3-16', 0.05, 0.05, df_inshorts)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:25:36.728631Z","iopub.execute_input":"2023-03-21T12:25:36.728974Z","iopub.status.idle":"2023-03-21T12:25:41.306434Z","shell.execute_reply.started":"2023-03-21T12:25:36.728917Z","shell.execute_reply":"2023-03-21T12:25:41.304859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save xsum\nsave_dataset('xsum_10-300_3-40', 0.1, 0.1, df_xsum)\nsave_dataset('xsum_10-300_3-40', 0.05, 0.05, df_xsum)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:25:41.308462Z","iopub.execute_input":"2023-03-21T12:25:41.308959Z","iopub.status.idle":"2023-03-21T12:26:05.104836Z","shell.execute_reply.started":"2023-03-21T12:25:41.308907Z","shell.execute_reply":"2023-03-21T12:26:05.103390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save xsum shorter\nsave_dataset('xsum_10-150_3-40', 0.1, 0.1, df_xsum_shorter)\nsave_dataset('xsum_10-150_3-40', 0.05, 0.05, df_xsum_shorter)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:26:05.107140Z","iopub.execute_input":"2023-03-21T12:26:05.108268Z","iopub.status.idle":"2023-03-21T12:26:06.538850Z","shell.execute_reply.started":"2023-03-21T12:26:05.108208Z","shell.execute_reply":"2023-03-21T12:26:06.537477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T12:26:34.323676Z","iopub.execute_input":"2023-03-21T12:26:34.324205Z","iopub.status.idle":"2023-03-21T12:26:34.331706Z","shell.execute_reply.started":"2023-03-21T12:26:34.324156Z","shell.execute_reply":"2023-03-21T12:26:34.330166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}